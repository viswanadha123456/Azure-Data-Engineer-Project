# Azure-Data-Engineer-Project
This project demonstrates an end-to-end data engineering pipeline built from scratch using modern Azure data technologies.

Project Description
In this project, I take you through an End-to-End Data Engineering solution, where I leverage powerful technologies like:
Azure Data Factory
Azure Data Lake Storage (ADLS Gen2)
Azure Databricks
Apache Spark (PySpark)
ðŸ‘‰ Databricks is used both for data processing and as the data warehouse, storing curated datasets in Delta format for analytics.
Architecture Overview
The project follows the Medallion Architecture implemented fully in Databricks:
Bronze Layer â€“ Raw data ingestion
Silver Layer â€“ Cleaned and transformed data
Gold Layer â€“ Analytics-ready curated data
All layers are stored in Azure Data Lake and managed using Delta Lake in Databricks.
Data Ingestion
Data is ingested from source systems using Azure Data Factory
Pipelines are scheduled and monitored.
Bronze Layer (Raw Data)
Raw data is stored in Azure Data Lake
Minimal transformations applied
Silver Layer (Cleaned Data)
Data is cleaned, validated, and transformed using Databricks & PySpark
Stored in Delta format

Repository Structure
â”œâ”€â”€ adf/
â”‚   â””â”€â”€ pipelines/
â”œâ”€â”€ databricks/
â”‚   â””â”€â”€ notebooks/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”œâ”€â”€ silver/
â”‚   â””â”€â”€ gold/
â””â”€â”€ README.md
